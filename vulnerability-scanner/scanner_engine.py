import requests
import re
import time
import urllib.parse
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from typing import List, Dict, Set, Optional, Callable
import json

class VulnerabilityScanner:
    def __init__(self, target_url: str, max_depth: int = 2, delay: float = 1.0, 
                 scan_types: List[str] = None, status_callback: Callable = None):
        self.target_url = target_url.rstrip('/')
        self.domain = urlparse(target_url).netloc
        self.max_depth = max_depth
        self.delay = delay
        self.scan_types = scan_types or ['xss', 'sqli', 'csrf']
        self.status_callback = status_callback
        self.visited_urls: Set[str] = set()
        self.vulnerabilities: List[Dict] = []
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # Payloads for different attack types
        self.sql_payloads = [
            "' OR '1'='1",
            "' OR '1'='1' --",
            "' OR '1'='1' #",
            "admin'--",
            '" OR "" = "',
            "' UNION SELECT NULL--",
            "1' OR '1'='1",
            "1' AND '1'='2",
            "'; DROP TABLE users; --",
            "' OR 1=1 --"
        ]
        
        self.xss_payloads = [
            "<script>alert(1)</script>",
            "<img src=x onerror=alert(1)>",
            "<svg onload=alert(1)>",
            "\"><script>alert(1)</script>",
            "';alert(1);//",
            "<iframe src=javascript:alert(1)>",
            "<body onload=alert(1)>",
            "<input onfocus=alert(1) autofocus>",
            "javascript:alert(1)",
            "<script>confirm(1)</script>"
        ]
        
        self.sql_error_patterns = [
            r"sql syntax.*mysql",
            r"warning.*mysql_",
            r"valid mysql result",
            r"postgresql.*error",
            r"warning.*pg_",
            r"valid postgresql result",
            r"microsoft.*odbc.*sql",
            r"oracle.*error",
            r"sqlite.*error",
            r"syntax error.*query",
            r"mysql_fetch",
            r"ora-[0-9]+",
            r"microsoft jet database",
            r"access database engine"
        ]

    def log(self, message: str, level: str = "INFO"):
        """Log messages via callback"""
        if self.status_callback:
            self.status_callback(message, level)

    def update_progress(self, current: int, total: int):
        """Update scan progress"""
        if total > 0:
            progress = int((current / total) * 100)
            if self.status_callback:
                self.status_callback(f"Progress: {current}/{total} URLs", "INFO", progress)

    def is_valid_url(self, url: str) -> bool:
        """Check if URL belongs to target domain"""
        try:
            parsed = urlparse(url)
            return parsed.netloc == self.domain or parsed.netloc == ""
        except:
            return False

    def crawl_website(self) -> List[str]:
        """Crawl website to discover URLs"""
        self.log("Starting web crawling...")
        urls_to_visit = [self.target_url]
        depth_map = {self.target_url: 0}
        
        while urls_to_visit:
            current_url = urls_to_visit.pop(0)
            current_depth = depth_map.get(current_url, 0)
            
            if current_url in self.visited_urls or current_depth > self.max_depth:
                continue
                
            try:
                self.log(f"Crawling: {current_url}")
                response = self.session.get(current_url, timeout=10)
                self.visited_urls.add(current_url)
                
                if response.status_code == 200 and 'text/html' in response.headers.get('content-type', ''):
                    soup = BeautifulSoup(response.content, 'html.parser')
                    
                    # Find all links
                    for link in soup.find_all('a', href=True):
                        full_url = urljoin(current_url, link['href'])
                        if self.is_valid_url(full_url) and full_url not in self.visited_urls:
                            if full_url not in depth_map:
                                depth_map[full_url] = current_depth + 1
                                urls_to_visit.append(full_url)
                
                time.sleep(self.delay)
                
            except Exception as e:
                self.log(f"Error crawling {current_url}: {str(e)}", "ERROR")
        
        self.log(f"Crawling complete. Found {len(self.visited_urls)} URLs")
        return list(self.visited_urls)

    def extract_forms(self, url: str) -> List[Dict]:
        """Extract forms from a webpage"""
        try:
            response = self.session.get(url, timeout=10)
            if response.status_code != 200:
                return []
                
            soup = BeautifulSoup(response.content, 'html.parser')
            forms = []
            
            for form in soup.find_all('form'):
                form_data = {
                    'action': urljoin(url, form.get('action', url)),
                    'method': form.get('method', 'get').lower(),
                    'inputs': []
                }
                
                # Extract input fields
                for input_tag in form.find_all(['input', 'textarea', 'select']):
                    input_data = {
                        'name': input_tag.get('name', ''),
                        'type': input_tag.get('type', 'text'),
                        'value': input_tag.get('value', '')
                    }
                    if input_data['name']:
                        form_data['inputs'].append(input_data)
                
                forms.append(form_data)
            
            return forms
            
        except Exception as e:
            self.log(f"Error extracting forms from {url}: {str(e)}", "ERROR")
            return []

    def test_sql_injection(self, url: str, forms: List[Dict]):
        """Test for SQL injection vulnerabilities"""
        if 'sqli' not in self.scan_types:
            return
            
        self.log("Testing for SQL Injection...")
        
        for form in forms:
            for payload in self.sql_payloads:
                try:
                    for input_field in form['inputs']:
                        if input_field['type'] not in ['submit', 'button', 'reset']:
                            test_data = {}
                            
                            for inp in form['inputs']:
                                if inp['type'] not in ['submit', 'button', 'reset']:
                                    test_data[inp['name']] = inp['value'] or 'test'
                            
                            test_data[input_field['name']] = payload
                            
                            if form['method'] == 'post':
                                response = self.session.post(form['action'], data=test_data, timeout=10)
                            else:
                                response = self.session.get(form['action'], params=test_data, timeout=10)
                            
                            response_text = response.text.lower()
                            for pattern in self.sql_error_patterns:
                                if re.search(pattern, response_text, re.IGNORECASE):
                                    vuln = {
                                        'vuln_type': 'SQL Injection',
                                        'url': form['action'],
                                        'parameter': input_field['name'],
                                        'payload': payload,
                                        'method': form['method'].upper(),
                                        'risk_level': 'HIGH',
                                        'description': 'SQL error detected, possible SQL injection vulnerability'
                                    }
                                    self.vulnerabilities.append(vuln)
                                    self.log(f"🚨 SQL Injection found: {form['action']} - {input_field['name']}", "CRITICAL")
                                    break
                    
                    time.sleep(self.delay)
                    
                except Exception as e:
                    self.log(f"Error testing SQL injection: {str(e)}", "ERROR")

    def test_xss(self, url: str, forms: List[Dict]):
        """Test for XSS vulnerabilities"""
        if 'xss' not in self.scan_types:
            return
            
        self.log("Testing for Cross-Site Scripting (XSS)...")
        
        for form in forms:
            for payload in self.xss_payloads:
                try:
                    for input_field in form['inputs']:
                        if input_field['type'] not in ['submit', 'button', 'reset']:
                            test_data = {}
                            
                            for inp in form['inputs']:
                                if inp['type'] not in ['submit', 'button', 'reset']:
                                    test_data[inp['name']] = inp['value'] or 'test'
                            
                            test_data[input_field['name']] = payload
                            
                            if form['method'] == 'post':
                                response = self.session.post(form['action'], data=test_data, timeout=10)
                            else:
                                response = self.session.get(form['action'], params=test_data, timeout=10)
                            
                            if payload in response.text:
                                vuln = {
                                    'vuln_type': 'Cross-Site Scripting (XSS)',
                                    'url': form['action'],
                                    'parameter': input_field['name'],
                                    'payload': payload,
                                    'method': form['method'].upper(),
                                    'risk_level': 'HIGH',
                                    'description': 'XSS payload reflected in response'
                                }
                                self.vulnerabilities.append(vuln)
                                self.log(f"🚨 XSS found: {form['action']} - {input_field['name']}", "CRITICAL")
                    
                    time.sleep(self.delay)
                    
                except Exception as e:
                    self.log(f"Error testing XSS: {str(e)}", "ERROR")

    def test_csrf(self, url: str, forms: List[Dict]):
        """Test for CSRF vulnerabilities"""
        if 'csrf' not in self.scan_types:
            return
            
        self.log("Testing for Cross-Site Request Forgery (CSRF)...")
        
        csrf_tokens = ['csrf', 'token', '_token', 'csrftoken', 'authenticity_token', 'csrf_token']
        
        for form in forms:
            if form['method'] == 'post':
                has_csrf_token = False
                
                for input_field in form['inputs']:
                    if input_field['type'] == 'hidden':
                        for token_name in csrf_tokens:
                            if token_name in input_field['name'].lower():
                                has_csrf_token = True
                                break
                
                if not has_csrf_token:
                    vuln = {
                        'vuln_type': 'Cross-Site Request Forgery (CSRF)',
                        'url': form['action'],
                        'parameter': 'N/A',
                        'payload': 'N/A',
                        'method': 'POST',
                        'risk_level': 'MEDIUM',
                        'description': 'POST form without CSRF protection detected'
                    }
                    self.vulnerabilities.append(vuln)
                    self.log(f"⚠️ CSRF vulnerability found: {form['action']}", "WARNING")

    def scan_url(self, url: str):
        """Scan a single URL for vulnerabilities"""
        self.log(f"Scanning: {url}")
        forms = self.extract_forms(url)
        
        if forms:
            self.log(f"Found {len(forms)} forms on {url}")
            self.test_sql_injection(url, forms)
            self.test_xss(url, forms)
            self.test_csrf(url, forms)
        else:
            self.log(f"No forms found on {url}")

    def run_scan(self) -> List[Dict]:
        """Run complete vulnerability scan"""
        try:
            self.log("Testing connection to target...")
            response = self.session.get(self.target_url, timeout=10)
            if response.status_code != 200:
                self.log(f"Warning: Target returned status code {response.status_code}", "WARNING")
            
            urls = self.crawl_website()
            
            self.log(f"Starting vulnerability scan on {len(urls)} URLs...")
            for i, url in enumerate(urls):
                self.scan_url(url)
                self.update_progress(i + 1, len(urls))
            
            self.log(f"Scan complete. Found {len(self.vulnerabilities)} vulnerabilities")
            return self.vulnerabilities
            
        except Exception as e:
            self.log(f"Scan failed: {str(e)}", "ERROR")
            return []
